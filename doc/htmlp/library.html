<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" 
 "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <!-- $Id: library.html,v 1.9 2007/08/20 09:55:20 deraugla Exp $ -->
  <!-- Copyright (c) 2007 INRIA -->
  <title>Library</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <link rel="stylesheet" type="text/css" href="styles/base.css"
        title="Normal" />
</head>
<body>

<div id="menu">
</div>

<div id="content">

<h1 class="top">Library</h1>

<div id="tableofcontents">
</div>

<h2>Stdpp module</h2>

<p>Building and combining locations (this module should be renamed
  "<tt>Ploc</tt>" one day).</p>

<dl>
  <dt><tt>type location = 'abstract;</tt></dt>
</dl>

<h3>located exceptions</h3>

<dl>
  <dt><tt>exception Exc_located of location and exn;</tt></dt>
  <dd>"<tt>Exc_located loc e</tt>" is an encapsulation of the
    exception "<tt>e</tt>" with the input location "<tt>loc</tt>". To
    be used to specify a location for an error. This exception must
    not be raised by "<tt>raise</tt>" but rather by
    "<tt>raise_with_loc</tt>" (see below), to prevent the risk of
    several encapsulations of "<tt>Exc_located</tt>".</dd>
  <dt><tt>value raise_with_loc : location -> exn -> 'a;</tt></dt>
  <dd>"<tt>raise_with_loc loc e</tt>", if "<tt>e</tt>" is already the
    exception "<tt>Exc_located</tt>", re-raise it (ignoring the new
    location "<tt>loc</tt>"), else raise the exception
    "<tt>Exc_located loc e</tt>".</dd>
</dl>

<h3>making locations</h3>

<dl>
  <dt><tt>value make_lined_loc : int -> int -> (int * int) ->
      location;</tt></dt>
  <dd>"<tt>make_lined_loc line_nb bol_pos (bp, ep)</tt>" creates a
    location starting at line number "<tt>line_nb</tt>", where the
    position of the beginning of the line is "<tt>bol_pos</tt>" and
    between the positions "<tt>bp</tt>" (included) and "<tt>ep</tt>"
    excluded. The positions are in number of characters since the
    begin of the stream.</dd>
  <dt><tt>value make_loc : (int * int) -> location;</tt></dt>
  <dd>"<tt>make_loc</tt>" is like "<tt>make_lined_loc</tt>" except
    that the line number is not provided (to be used e.g. when the
    line number is unknown).</dd>
</dl>

<dl>
  <dt><tt>value dummy_loc : location;</tt></dt>
  <dd>"<tt>dummy_loc</tt>" is a dummy location, used in situations
    when location has no meaning.</dd>
</dl>

<h3>getting location info</h3>

<dl>
  <dt><tt>value first_pos : location -> int;</tt></dt>
  <dd>"<tt>first_pos loc</tt>" returns the position of the begin of
    the location in number of characters since the beginning of the
    stream.</dd>
  <dt><tt>value last_pos : location -> int;</tt></dt>
  <dd>"<tt>first_pos loc</tt>" returns the position of the first
    character not of the location in number of characters since the
    beginning of the stream.</dd>
  <dt><tt>value line_nb : location -> int;</tt></dt>
  <dd>"<tt>line_nb loc</tt>" returns the line number of the location
    or "<tt>-1</tt>" if the location does not contain a line number
    (i.e. built the old way with "<tt>make_loc</tt>" above.</dd>
  <dt><tt>value bol_pos : location -> int;</tt></dt>
  <dd>"<tt>line_nb loc</tt>" returns the position of the beginning of
    the line of the location in number of characters since the
    beginning of the stream, or "<tt>0</tt>" if the location does not
    contain a line number (i.e. built the old with with
    "<tt>make_loc</tt>" above.</dd>
</dl>

<h3>combining locations</h3>

<dl>
  <dt><tt>value encl_loc : location -> location -> location;</tt></dt>
  <dd>"<tt>encl_loc loc1 loc2</tt>" returns the location starting at
    the smallest start and ending at the greatest end of the locations
    "<tt>loc1</tt>" and "<tt>loc2</tt>". In other words, it is the
    location enclosing "<tt>loc1</tt>" and "<tt>loc2</tt>".</dd>
  <dt><tt>value shift_loc : int -> location -> location;</tt></dt>
  <dd>"<tt>shift_loc sh loc</tt>" returns the location "<tt>loc</tt>"
    shifted with "<tt>sh</tt>" characters. The line number is not
    recomputed.</dd>
  <dt><tt>value sub_loc : location -> int -> int -> location;</tt></dt>
  <dd>"<tt>sub_loc loc sh len</tt>" is the location "<tt>loc</tt>"
    shifted with "<tt>sh</tt>" characters and with length
    "<tt>len</tt>". The previous ending position of the location is
    lost.</dd>
  <dt><tt>value after_loc : location -> int -> int -> location;</tt></dt>
  <dd>"<tt>after_loc loc sh len</tt>" is the location just after loc
    (starting at the end position of "<tt>loc</tt>") shifted with
    "<tt>sh</tt>" characters and of length "<tt>len</tt>".</dd>
</dl>

<h3>miscellaneous</h3>

<dl>
  <dt><tt>value loc_name : ref string;</tt></dt>
  <dd>"<tt>loc_name.val</tt>" is the name of the location variable
    used in grammars and in the predefined quotations for OCaml syntax
    trees. Default: "<tt>"loc"</tt>".</dd>
</dl>

<dl>
  <dt><tt>value line_of_loc : string -> location -> (string * int *
      int * int);</tt></dt>
  <dd>"<tt>line_of_loc fname loc</tt>" reads the file "<tt>fname</tt>"
    up to the location "<tt>loc</tt>" and returns the real input file,
    the line number and the characters location in the line; the real
    input file can be different from "<tt>fname</tt>" because of
    possibility of line directives typically generated by
    /lib/cpp.</dd>
</dl>

<h2>Token module</h2>

<p>Lexing for camlp5 grammars.</p>

<p>This module defines the Camlp5 lexer type to be used in extensible
  grammars (see module "<tt>Grammar</tt>"). It also provides some
  useful functions to create lexers (this module should be renamed
  "<tt>Plexing</tt>" one day).</p>

<dl>
  <dt><tt>type pattern = (string * string);</tt></dt>
  <dd>Type for values used by the generated code of the EXTEND
    statement to represent terminals in entry rules.
  <ul>
    <li>The first string is the constructor name (must start with an
      uppercase character). When it is empty, the second string is
      supposed to be a keyword.</li>
    <li>The second string is the constructor parameter. Empty if it
      has no parameter (corresponding to the 'wildcard' pattern).</li>
    <li>The way tokens patterns are interpreted to parse tokens is
      done by the lexer, function "<tt>tok_match</tt>" below.</li>
    </ul>
  </dd>
</dl>

<dl>
  <dt><tt>exception Error of string;</tt></dt>
  <dd>A lexing error exception to be used by lexers.</dd>
</dl>

<h3>Lexer type</h3>

<pre style="border:0; margin-left: 1cm">
type glexer 'te =
  { tok_func : lexer_func 'te;
    tok_using : pattern -> unit;
    tok_removing : pattern -> unit;
    tok_match : mutable pattern -> 'te -> string;
    tok_text : pattern -> string;
    tok_comm : mutable option (list Stdpp.location) }
</pre>

<dl><dd>
    The type for lexers compatible with camlp5 grammars. The parameter
    type "<tt>'te</tt>" is the type of the tokens.
    <ul>
      <li>The field "<tt>tok_func</tt>" is the main lexer
        function. See "<tt>lexer_func</tt>" type below.</li>
      <li>The field "<tt>tok_using</tt>" is a function called by the
        "<tt>EXTEND</tt>" statement to warn the lexer that a rule uses
        this pattern (given as parameter). This allow the lexer 1/ to
        check that the pattern constructor is really among its
        possible constructors 2/ to enter the keywords in its
        tables.</li>
      <li>The field "<tt>tok_removing</tt>" is a function possibly
        called by the "<tt>DELETE_RULE</tt>" statement to warn the
        lexer that this pattern (given as parameter) is no more used
        in the grammar (the grammar system maintains a number of usages
        of all patterns and calls this function when this number falls
        to zero). If it is a keyword, this allow the lexer to remove
        it in its tables.</li>
      <li>The field "<tt>tok_match</tt>" is a function called by the
        camlp5 grammar system to ask the lexer how the input tokens
        have to be matched against the patterns. Warning: for
        efficiency, this function has to be written as a function
        taking patterns as parameters and, for each pattern value,
        returning a function matching a token, <em>not</em> as a
        function with two parameters.</li>
      <li>The field "<tt>tok_text</tt>" is a function called by the
        grammar system to get the name of the tokens for the error
        messages, in case of syntax error, or for the displaying of
        the rules of an entry.</li>
      <li>The field "<tt>tok_comm</tt>" is a mutable place where the
        lexer can put the locations of the comments, if its initial
        value is not "<tt>None</tt>". If it is "<tt>None</tt>",
        nothing has to be done by the lexer.</li>
    </ul>
</dd></dl>

<dl>
  <dt><tt>and lexer_func 'te = Stream.t char -> (Stream.t 'te *
      location_function)</tt></dt>
  <dd>The type of a lexer function (field "<tt>tok_func</tt>" of the
    type "<tt>glexer</tt>"). The character stream is the input stream
    to be lexed. The result is a pair of a token stream and a location
    function (see below) for this tokens stream.</dd>
</dl>

<dl>
  <dt><tt>and location_function = int -> Stdpp.location;</tt></dt>
  <dd>The type of a function giving the location of a token in the
    source from the token number in the stream (starting from
    zero).</dd>
</dl>

<dl>
  <dt><tt>value lexer_text : pattern -> string;</tt></dt>
  <dd>A simple "<tt>tok_text</tt>" function.</dd>
</dl>

<dl>
  <dt><tt>value default_match : pattern -> (string * string) ->
      string;</tt></dt>
  <dd>A simple "<tt>tok_match</tt>" function, appling to the token
       type "<tt>(string * string)</tt>".</dd>
</dl>

<h3>Lexers from parsers or ocamllex</h3>

<p>The functions below create lexer functions either from a "<tt>char
   stream</tt>" parser or for an "<tt>ocamllex</tt>" function. With
   the returned function "<tt>f</tt>", it is possible to get a simple
   lexer (of the type "<tt>Token.glexer</tt>" above):</p>

<pre>
   { Token.tok_func = f;
     Token.tok_using = (fun _ -> ());
     Token.tok_removing = (fun _ -> ());
     Token.tok_match = Token.default_match;
     Token.tok_text = Token.lexer_text }
</pre>

<p>Note that a better "<tt>tok_using</tt>" function should check the
  used tokens and raise "<tt>Token.Error</tt>" for incorrect ones. The
  other functions "<tt>tok_removing</tt>", "<tt>tok_match</tt>" and
  "<tt>tok_text</tt>" may have other implementations as well.</p>

<pre style="border:0; margin-left: 1cm">
value lexer_func_of_parser :
  ((Stream.t char * ref int * ref int) -> ('te * Stdpp.location)) ->
     lexer_func 'te;
</pre>

<dl><dd>A lexer function from a lexer written as a char stream parser
    returning the next token and its location. The two references
    with the char stream contain the current line number and the
    position of the beginning of the current line.
</dd></dl>

<pre style="border:0; margin-left: 1cm">
value lexer_func_of_ocamllex : (Lexing.lexbuf -> 'te) -> lexer_func 'te;
</pre>

<dl><dd>
    A lexer function from a lexer created by "<tt>ocamllex</tt>".
</dd></dl>

<h3>Function to build a stream and a location function</h3>

<pre style="border:0; margin-left: 1cm">
value make_stream_and_location :
  (unit -> ('te * Stdpp.location)) -> (Stream.t 'te * location_function);
</pre>

<h3>Useful functions and values</h3>

<dl>
  <dt><tt>value eval_char : string -> char;</tt></dt>
  <dt><tt>value eval_string : Stdpp.location -> string -> string;</tt></dt>
  <dd>Convert a char or a string token, where the backslashes had not
    been interpreted into a real char or string; raise
    "<tt>Failure</tt>" if bad backslash sequence found;
    "<tt>Token.eval_char (Char.escaped c)</tt>" would returns
    "<tt>c</tt>" and "<tt>Token.eval_string (String.escaped s)</tt>"
    would return "<tt>s</tt>".</dd>
</dl>

<dl>
  <dt><tt>value restore_lexing_info : ref (option (int * int));</tt></dt>
  <dt><tt>value line_nb : ref (ref int);</tt></dt>
  <dt><tt>value bol_pos : ref (ref int);</tt></dt>
  <dd>Special variables used to reinitialize line numbers and position
    of beginning of line with their correct current values when a parser
    is called several times with the same character stream. Necessary
    for directives (e.g. #load or #use) which interrupt the parsing.
    Without usage of these variables, locations after the directives
    can be wrong.</dd>
</dl>

<h3>Backward compatibilities</h3>

<p>Deprecated since version 4.08.</p>

<dl>
  <dt><tt>type location = Stdpp.location;</tt></dt>
  <dt><tt>value make_loc : (int * int) -> location;</tt></dt>
  <dt><tt>value dummy_loc : location;</tt></dt>
</dl>

<h2>Plexer module</h2>

<p>This module contains a lexer used for ocaml syntax (revised and
  normal).</p>

<h3>lexer</h3>

<dl>
  <dt><tt>value gmake : unit -> Token.glexer (string * string);</tt></dt>
  <dd>"<tt>gmake ()</tt>" returns a lexer compatible with the
    extensible grammars.  The returned tokens follow the normal syntax
    and the revised syntax lexing rules.</dd>
</dl>

<p>The token type is "<tt>(string * string)</tt>" just like the pattern
  type.</p>

<p>The meaning of the tokens are:</p>

<ul>
  <li><tt>("", s)</tt> is the keyword "<tt>s</tt>",</li>
  <li><tt>("LIDENT", s)</tt> is the ident "<tt>s</tt>" starting with a
    lowercase letter,</li>
  <li><tt>("UIDENT", s)</tt> is the ident "<tt>s</tt>" starting with
    an uppercase letter,</li>
  <li><tt>("INT", s)</tt> is an integer constant whose string source
    is "<tt>s</tt>",</li>
  <li><tt>("INT_l", s)</tt> is an 32 bits integer constant whose
    string source is "<tt>s</tt>",</li>
  <li><tt>("INT_L", s)</tt> is an 64 bits integer constant whose
    string source is "<tt>s</tt>",</li>
  <li><tt>("INT_n", s)</tt> is an native integer constant whose string
    source is "<tt>s</tt>",</li>
  <li><tt>("FLOAT", s)</tt> is a float constant whose string source is
    "<tt>s</tt>",</li>
  <li><tt>("STRING", s)</tt> is the string constant "<tt>s</tt>",</li>
  <li><tt>("CHAR", s)</tt> is the character constant
    "<tt>s</tt>",</li>
  <li><tt>("TILDEIDENT", s)</tt> is the tilde character "<tt>~</tt>"
    followed by the ident "<tt>s</tt>",</li>
  <li><tt>("TILDEIDENTCOLON", s)</tt> is the tilde character
    "<tt>~</tt>" followed by the ident "<tt>s</tt>" and a colon
    "<tt>:</tt>",</li>
  <li><tt>("QUESTIONIDENT", s)</tt> is the question mark "<tt>?</tt>"
    followed by the ident "<tt>s</tt>",</li>
  <li><tt>("QUESTIONIDENTCOLON", s)</tt> is the question mark
    "<tt>?</tt>" followed by the ident "<tt>s</tt>" and a colon
    "<tt>:</tt>",</li>
  <li><tt>("QUOTATION", "t:s")</tt> is a quotation "<tt>t</tt>"
    holding the string "<tt>s</tt>",</li>
  <li><tt>("ANTIQUOT", "t:s")</tt> is an antiquotation "<tt>t</tt>"
    holding the string "<tt>s</tt>",</li>
  <li><tt>("EOI", "")</tt> is the end of input.</li>
</ul>

<p>The associated token patterns in the EXTEND statement hold the same
  names than the first string (constructor name) of the tokens
  expressions above.</p>

<p>Warning: the string associated with the "<tt>STRING</tt>"
  constructor is the string found in the source without any
  interpretation. In particular, the backslashes are not
  interpreted. For example, if the input is <tt>"\n"</tt> the string
  is *not* a string with one element containing the "newline"
  character, but a string of two elements: the backslash and the
  <tt>"n"</tt> letter.</p>

<p>Same thing for the string associated with the "<tt>CHAR</tt>"
  constructor.</p>

<p>The functions "<tt>Token.eval_string</tt>" and
  "<tt>Token.eval_char</tt>" allow to convert them into the real
  corresponding string or char value.</p>

<h3>flags</h3>

<dl>
  <dt><tt>value dollar_for_antiquotation : ref bool;</tt></dt>
  <dd>When True (default), the next call to "<tt>Plexer.gmake ()</tt>"
    returns a lexer where the dollar sign is used for antiquotations.
    If False, there is no antiquotations and the dollar sign can be
    used as normal token.</dd>
</dl>

<dl>
  <dt><tt>value specific_space_dot : ref bool;</tt></dt>
  <dd>When "<tt>False</tt>" (default), the next call to
    "<tt>Plexer.gmake ()</tt>" returns a lexer where there is no
    difference between dots which have spaces before and dots which
    don't have spaces before. If "<tt>True</tt>", dots which have
    spaces before return the keyword <tt>" ."</tt> (space dot) and the
    ones which don't have spaces before return the
    keyword <tt>"."</tt>  (dot alone).</dd>
</dl>

<dl>
  <dt><tt>value no_quotations : ref bool;</tt></dt>
  <dd>When "<tt>True</tt>", all lexers built by "<tt>Plexer.make
      ()</tt>" do not lex the quotation syntax. Default is
      "<tt>False</tt>" (quotations are lexed).</dd>
</dl>

<h2>Gramext module</h2>

<p>This module shows in clear the implementation of grammars and
  entries types, the normal access being through the
  "<tt>Grammar</tt>" module where these types are abstract.</p>

<h3>Grammar type</h3>

<pre style="border:0; margin-left: 1cm">
type grammar 'te =
  { gtokens : Hashtbl.t Token.pattern (ref int);
    glexer : mutable Token.glexer 'te }
;
</pre>

<dl><dd>
  The visible type of grammars, i.e. the implementation of the abstract
  type "<tt>Grammar.g</tt>". It is also the implementation of an internal
  grammar type used in the Grammar functorial interface.
</dl></dd>

<dl><dd>
  The type parameter "<tt>'te</tt>" is the type of the tokens, which
  is "<tt>(string * string)</tt>" for grammars built with
  "<tt>Grammar.gcreate</tt>", and any type for grammars built with the
  functorial interface. The field "<tt>gtokens</tt>" records the
  count of usages of each token pattern, allowing to call the lexer
  function "<tt>tok_removing</tt>" (see the
    <a href="#a:Token-module">Token module</a>) when this count reaches
    zero. The field "<tt>glexer</tt>" is the lexer.
</dd></dl>

<h3>Entry type</h3>

<pre style="border:0; margin-left: 1cm">
type g_entry 'te =
  { egram : grammar 'te;
    ename : string;
    elocal : bool;
    estart : mutable int -> Stream.t 'te -> Obj.t;
    econtinue : mutable int -> int -> Obj.t -> Stream.t 'te -> Obj.t;
    edesc : mutable g_desc 'te }
</pre>

<dl><dd>
    The visible type for grammar entries, i.e. the implementation of
    the abstract type "<tt>Grammar.Entry.e</tt>" and the type of
    entries in the Grammar functorial interface. Notice that these
    entry types have a type parameter which does not appear in the
    "<tt>g_entry</tt>" type (the "<tt>'te</tt>" parameter is, like for
    grammars above, the type of the tokens). This is due to the
    specific typing system of the EXTEND statement which sometimes
    has to hide real types, the ocaml normal type system not being
    able to type camlp5 grammars.
</dd></dl>

<pre style="border:0; margin-left: 1cm">
and g_desc 'te =
  [ Dlevels of list (g_level 'te)
  | Dparser of Stream.t 'te -> Obj.t ]
and g_level 'te =
  { assoc : g_assoc;
    lname : option string;
    lsuffix : g_tree 'te;
    lprefix : g_tree 'te }
and g_assoc = [ NonA | RightA | LeftA ]
and g_symbol 'te =
  [ Smeta of string and list (g_symbol 'te) and Obj.t
  | Snterm of g_entry 'te
  | Snterml of g_entry 'te and string
  | Slist0 of g_symbol 'te
  | Slist0sep of g_symbol 'te and g_symbol 'te
  | Slist1 of g_symbol 'te
  | Slist1sep of g_symbol 'te and g_symbol 'te
  | Sopt of g_symbol 'te
  | Sflag of g_symbol 'te
  | Sself
  | Snext
  | Stoken of Token.pattern
  | Stree of g_tree 'te ]
and g_action = Obj.t
and g_tree 'te =
  [ Node of g_node 'te
  | LocAct of g_action and list g_action
  | DeadEnd ]
and g_node 'te =
  { node : g_symbol 'te; son : g_tree 'te; brother : g_tree 'te }
;
</pre>

<p>... the following lines have to be structured ...</p>

<pre>

type position =
  [ First
  | Last
  | Before of string
  | After of string
  | Level of string ]
;

value levels_of_rules :
  g_entry 'te -> option position ->
    list
      (option string * option g_assoc *
       list (list (g_symbol 'te) * g_action)) ->
    list (g_level 'te);
value srules : list (list (g_symbol 'te) * g_action) -> g_symbol 'te;
external action : 'a -> g_action = "%identity";

value delete_rule_in_level_list :
  g_entry 'te -> list (g_symbol 'te) -> list (g_level 'te) ->
    list (g_level 'te);

value warning_verbose : ref bool;
</pre>

<h2>Grammar module</h2>

<p>... to be written ...</p>

<h2>Extfold module</h2>

<p>... to be written ...</p>

<h2>Extfun module</h2>

<p>... to be written ...</p>

<h2>Eprinter module</h2>

<p>... to be written ...</p>

<h2>Fstream module</h2>

<p>... to be written ...</p>

<h2>Pretty module</h2>

<p>... to be written ...</p>

<div class="trailer">
</div>

</div>

</body>
</html>
